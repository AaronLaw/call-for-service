{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Data Loading, Cleaning, and Normalization\n",
    "We need to load the data from .csv into Postgres.  We also need to normalize the data to make analysis easy.  We'll use Pandas to deal with the .csv loading and data storage.\n",
    "\n",
    "Files we need to load:\n",
    "- cfs_2014_inmain.csv (CFS data)\n",
    "- cfs_xxx2014_incilog.csv (CFS event data -- one for each month)\n",
    "- cfs_2014_lwmain.csv (incident data)\n",
    "- cfs_2014_lwmodop.csv (incident modus operandi data)\n",
    "- LWMAIN.THING.csv (incident lookup tables, where THING is one of the following: CSSTATUS, EMDIVISION, EMSECTION, EMUNIT, INSTSTATS, PREMISE, or WEAPON)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns in files:\n",
    "*inmain*\n",
    "\n",
    "inci_id\tcalltime\tcalldow\tcase_id\tcallsource\tprimeunit\tfirstdisp\tstreetno\tstreetonly\tstreet\tcitydesc\tzip\tcrossroad1\tcrossroad2\tgeox\tgeoy\tservice\tagency\tstatbeat\tdistrict\tra\tbusiness\tnaturecode\tnature\tpriority\trptonly\tcancelled\tnotes\ttimeroute\tsecs2rt\ttimefini\tsecs2fn\tfirstdtm\tsecs2di\tsecsrt2dsp\tsecsfi2dsp\tfirstenr\tsecs2en\tsecsdi2en\tfirstarrv\tsecs2ar\tsecsdi2ar\tfirsttran\tsecs2tr\tsecsar2tr\tlastclr\tsecs2lc\tsecsar2lc\tsecstr2lc\ttimeclose\treptaken\tclosecode\tclosecomm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine # database connection\n",
    "import datetime as dt\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inci_id</th>\n",
       "      <th>calltime</th>\n",
       "      <th>calldow</th>\n",
       "      <th>case_id</th>\n",
       "      <th>callsource</th>\n",
       "      <th>primeunit</th>\n",
       "      <th>firstdisp</th>\n",
       "      <th>streetno</th>\n",
       "      <th>streetonly</th>\n",
       "      <th>street</th>\n",
       "      <th>...</th>\n",
       "      <th>secs2tr</th>\n",
       "      <th>secsar2tr</th>\n",
       "      <th>lastclr</th>\n",
       "      <th>secs2lc</th>\n",
       "      <th>secsar2lc</th>\n",
       "      <th>secstr2lc</th>\n",
       "      <th>timeclose</th>\n",
       "      <th>reptaken</th>\n",
       "      <th>closecode</th>\n",
       "      <th>closecomm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014000002</td>\n",
       "      <td>1/1/14 0:00:22</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PHONE</td>\n",
       "      <td>BK2</td>\n",
       "      <td>BK2</td>\n",
       "      <td>301</td>\n",
       "      <td>S ELM ST</td>\n",
       "      <td>301 S ELM ST</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1/1/14 0:04:20</td>\n",
       "      <td>238</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1/1/14 0:04:22</td>\n",
       "      <td></td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014000003</td>\n",
       "      <td>1/1/14 0:00:40</td>\n",
       "      <td>4</td>\n",
       "      <td>14000001</td>\n",
       "      <td>SELF</td>\n",
       "      <td>B200</td>\n",
       "      <td>B200</td>\n",
       "      <td>1610</td>\n",
       "      <td>GUESS RD</td>\n",
       "      <td>1610 GUESS RD</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1/1/14 0:15:57</td>\n",
       "      <td>918</td>\n",
       "      <td>917</td>\n",
       "      <td>0</td>\n",
       "      <td>1/1/14 0:15:59</td>\n",
       "      <td>B200</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      inci_id        calltime  calldow   case_id callsource primeunit  \\\n",
       "0  2014000002  1/1/14 0:00:22        4       NaN      PHONE    BK2      \n",
       "1  2014000003  1/1/14 0:00:40        4  14000001      SELF     B200     \n",
       "\n",
       "    firstdisp  streetno streetonly         street    ...    secs2tr  \\\n",
       "0  BK2              301   S ELM ST   301 S ELM ST    ...          0   \n",
       "1  B200            1610   GUESS RD  1610 GUESS RD    ...          0   \n",
       "\n",
       "   secsar2tr         lastclr secs2lc  secsar2lc  secstr2lc       timeclose  \\\n",
       "0          0  1/1/14 0:04:20     238          0          0  1/1/14 0:04:22   \n",
       "1          0  1/1/14 0:15:57     918        917          0  1/1/14 0:15:59   \n",
       "\n",
       "  reptaken  closecode closecomm  \n",
       "0                  10       NaN  \n",
       "1   B200            1       NaN  \n",
       "\n",
       "[2 rows x 53 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(pd.read_csv('csv_data/cfs_2014_inmain.csv', nrows=2).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "engine = create_engine('postgresql://localhost/cfs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##cfs_2014_inmain.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start = dt.datetime.now()\n",
    "chunksize = 20000\n",
    "j = 0\n",
    "index_start = 1\n",
    "\n",
    "for df in pd.read_csv('311_100M.csv', chunksize=chunksize, iterator=True, encoding='utf-8'):\n",
    "    \n",
    "    df = df.rename(columns={c: c.replace(' ', '') for c in df.columns}) # Remove spaces from columns\n",
    "\n",
    "    df['CreatedDate'] = pd.to_datetime(df['CreatedDate']) # Convert to datetimes\n",
    "    df['ClosedDate'] = pd.to_datetime(df['ClosedDate'])\n",
    "\n",
    "    df.index += index_start\n",
    "\n",
    "    # Remove the un-interesting columns\n",
    "    columns = ['Agency', 'CreatedDate', 'ClosedDate', 'ComplaintType', 'Descriptor',\n",
    "               'CreatedDate', 'ClosedDate', 'TimeToCompletion',\n",
    "               'City']\n",
    "\n",
    "    for c in df.columns:\n",
    "        if c not in columns:\n",
    "            df = df.drop(c, axis=1)    \n",
    "\n",
    "    \n",
    "    j+=1\n",
    "    print '{} seconds: completed {} rows'.format((dt.datetime.now() - start).seconds, j*chunksize)\n",
    "\n",
    "    df.to_sql('data', disk_engine, if_exists='append')\n",
    "    index_start = df.index[-1] + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Initial Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial exploration of the Durham PD CFS data using non-robust .csv reading code.  Has windows line endings, so have to open the file in universal mode to account for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "first = True\n",
    "incilog_header = \"\"\n",
    "incilog = []\n",
    "\n",
    "with open(\"cfs_mar2015_incilog.csv\",\"rU\") as f:\n",
    "    for line in f.readlines():\n",
    "        if first:\n",
    "            incilog_header = line\n",
    "            first = False\n",
    "        else:\n",
    "            incilog.append([datum.strip() for datum in line.split(',')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['63260886',\n",
      " 'RPTO',\n",
      " 'Report Only',\n",
      " '3/27/15 15:22:41',\n",
      " '55361',\n",
      " '2014412231',\n",
      " 'B125',\n",
      " 'R',\n",
      " '997150',\n",
      " '']\n"
     ]
    }
   ],
   "source": [
    "pprint(incilog[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "first = True\n",
    "inmain_header = \"\"\n",
    "inmain = []\n",
    "\n",
    "with open(\"cfs_mar2015_inmain.csv\",\"rU\") as f:\n",
    "    for line in f.readlines():\n",
    "        if first:\n",
    "            inmain_header = line\n",
    "            first = False\n",
    "        else:\n",
    "            inmain.append([datum.strip() for datum in line.split(',')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2015087068',\n",
      " '3/1/15 0:00:32',\n",
      " '1',\n",
      " '',\n",
      " 'E911',\n",
      " 'C413',\n",
      " 'C424',\n",
      " '617',\n",
      " 'HOPE AVE',\n",
      " '617 HOPE AVE',\n",
      " 'DURHAM',\n",
      " '27707',\n",
      " 'ANACOSTA ST',\n",
      " 'LINCOLN ST',\n",
      " '2030390.25',\n",
      " '807470.19',\n",
      " 'LAW',\n",
      " 'DPD',\n",
      " '412',\n",
      " 'D4',\n",
      " 'STH',\n",
      " '',\n",
      " 'ASSIST',\n",
      " 'ASSIST PERSON',\n",
      " '4',\n",
      " '0',\n",
      " '0',\n",
      " 'actve dist...child advised mom and aunt aruging  [03/01/15 00:01:14 SMITHK]  WRLS  [03/01/15 00:01:19 SMITHK]  NO PHASE 2.....EHX SHOWS 500 MAHONE POSS APT1  [03/01/15 00:04:09 SMITHK]  [EPD] Aborted by Law Priority with code: 1. Caller hung up  [03/01/15 00:07:42 SMITHK]  {C413} NEED BETTER LOCATION  [03/01/15 00:09:50 ROSSA]',\n",
      " '3/1/15 0:04:11',\n",
      " '219',\n",
      " '3/1/15 0:08:11',\n",
      " '459',\n",
      " '3/1/15 0:04:53',\n",
      " '261',\n",
      " '42',\n",
      " '0',\n",
      " '3/1/15 0:04:53',\n",
      " '261',\n",
      " '0',\n",
      " '3/1/15 0:09:32',\n",
      " '540',\n",
      " '279',\n",
      " 'NULL',\n",
      " '0',\n",
      " '0',\n",
      " '3/1/15 0:34:42',\n",
      " '2050',\n",
      " '1510',\n",
      " '0',\n",
      " '3/1/15 0:34:43',\n",
      " '',\n",
      " '10',\n",
      " '']\n"
     ]
    }
   ],
   "source": [
    "pprint(inmain[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dispatcher's remarks are all concatenated together, separated by brackets containing what appear to be timestamps and names.  We'll use regexes to pull these apart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['actve dist...child advised mom and aunt aruging  ',\n",
      " '03/01/15 00:01:14',\n",
      " 'SMITHK',\n",
      " '  WRLS  ',\n",
      " '03/01/15 00:01:19',\n",
      " 'SMITHK',\n",
      " '  NO PHASE 2.....EHX SHOWS 500 MAHONE POSS APT1  ',\n",
      " '03/01/15 00:04:09',\n",
      " 'SMITHK',\n",
      " '  [EPD] Aborted by Law Priority with code: 1. Caller hung up  ',\n",
      " '03/01/15 00:07:42',\n",
      " 'SMITHK',\n",
      " '  {C413} NEED BETTER LOCATION  ',\n",
      " '03/01/15 00:09:50',\n",
      " 'ROSSA',\n",
      " '']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "timestamp_expr = re.compile(\"\\[(\\d{2}/\\d{2}/\\d{2} \\d{2}:\\d{2}:\\d{2}) (.+?)\\]\")\n",
    "\n",
    "test_str = \"actve dist...child advised mom and aunt aruging  [03/01/15 00:01:14 SMITHK]  \\\n",
    "WRLS  [03/01/15 00:01:19 SMITHK]  \\\n",
    "NO PHASE 2.....EHX SHOWS 500 MAHONE POSS APT1  [03/01/15 00:04:09 SMITHK]  \\\n",
    "[EPD] Aborted by Law Priority with code: 1. Caller hung up  [03/01/15 00:07:42 SMITHK]  \\\n",
    "{C413} NEED BETTER LOCATION  [03/01/15 00:09:50 ROSSA]\"\n",
    "\n",
    "pprint(timestamp_expr.split(test_str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a function we can use to get the data for each individual note."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('actve dist...child advised mom and aunt aruging',\n",
      "  datetime.datetime(2015, 3, 1, 0, 1, 14),\n",
      "  'SMITHK'),\n",
      " ('WRLS', datetime.datetime(2015, 3, 1, 0, 1, 19), 'SMITHK'),\n",
      " ('NO PHASE 2.....EHX SHOWS 500 MAHONE POSS APT1',\n",
      "  datetime.datetime(2015, 3, 1, 0, 4, 9),\n",
      "  'SMITHK'),\n",
      " ('[EPD] Aborted by Law Priority with code: 1. Caller hung up',\n",
      "  datetime.datetime(2015, 3, 1, 0, 7, 42),\n",
      "  'SMITHK'),\n",
      " ('{C413} NEED BETTER LOCATION',\n",
      "  datetime.datetime(2015, 3, 1, 0, 9, 50),\n",
      "  'ROSSA')]\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "def split_notes(notes):\n",
    "    \"\"\"\n",
    "    Return a list of 3-tuples.  Each tuple represents a single note and contains the timestamp, the note-taker, and\n",
    "    the text of the note.\n",
    "    \"\"\"\n",
    "    tuples = []\n",
    "    regex_split = timestamp_expr.split(notes)[:-1]  # get rid of the last empty string created by the split\n",
    "    for i in range(0,len(regex_split),3):\n",
    "        note = regex_split[i].strip()\n",
    "        timestamp = datetime.datetime.strptime(regex_split[i+1], \"%m/%d/%y %H:%M:%S\")\n",
    "        notetaker = regex_split[i+2]\n",
    "        tuples.append((note,timestamp,notetaker))\n",
    "    return tuples\n",
    "\n",
    "pprint(split_notes(test_str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questions we need answered about some of the fields:\n",
    "\n",
    "inmain\n",
    "- can we get any more info about the cases from the case_id? (case_id: case number, if a report is generated from the call)\n",
    "- callsources: E911, ALARM self-explanatory, but SELF, PHONE and RADIO?\n",
    "- primeunit: what are the responsibilities of the prime unit?\n",
    "- service is always LAW, agency is always DPD\n",
    "- nature/naturecode: differences between HANG UP, HANG UP WIRELESS PHASE 1, and HANG UP WIRELESS PHASE 2?\n",
    "- notes: need abbreviations used, can maybe get some of them from the nature codes\n",
    "- meanings of closecodes?\n",
    "\n",
    "incilog\n",
    "- each unit = one officer? any additional info we can get from unitper table, such as officer pay to more accurately estimate cost?\n",
    "\n",
    "assuming \"code_agcy\" for all since that matches up best with the data\n",
    "lwmain.csstatus\n",
    "- which code (code_fbi, code_sbi, code_agcy) is the one corresponding to the csstatus foreign key? (assuming code_agcy) are any columns other than descriptn informative?\n",
    "\n",
    "same questions for lwmain.emdivision, emsection, emunit, invststats, premise, weapon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " (eventually) Here we'll create the database schema to store the CFS data in a more structured way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# I think we're actually going to use postgres -- maybe not worry about the specific db implementation for now\n",
    "\n",
    "import sqlite3\n",
    "conn = sqlite3.connect('dpd_cfs.db')\n",
    "c = conn.cursor()\n",
    "\n",
    "CREATE_INCIDENT = \\\n",
    "\\\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS incident (\n",
    "    inci_id INTEGER PRIMARY KEY,\n",
    "    calltime TIMESTAMP,\n",
    "    calldow INTEGER,\n",
    "    case_id INTEGER,\n",
    "    callsource VARCHAR,\n",
    "    primeunit VARCHAR,\n",
    "    firstdisp VARCHAR,\n",
    "    streetno INTEGER,\n",
    "    streetonly VARCHAR,\n",
    "    street VARCHAR,\n",
    "    citydesc VARCHAR,\n",
    "    zip INTEGER,\n",
    "    crossroad1 VARCHAR,\n",
    "    crossroad2 VARCHAR,\n",
    "    geox DOUBLE,\n",
    "    geoy DOUBLE,\n",
    "    service VARCHAR,\n",
    "    agency VARCHAR,\n",
    "    \n",
    "    )\n",
    "\\\"\"\"\n",
    "\n",
    "c.execute('')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
